description: "e150 model v5"
runner: r002
SINGLE_FOLD: false
split:
    split_type: abhishek5
    split_num: 5
    shuffle: true
    random_state: 71
loader:
    trn_sampler_type: random
    trn_batch_size: 96
    tst_sampler_type: sequential
    tst_batch_size: 96
    dataset_type: tse_headtail_segmentation_dataset_v3
dataset:
    tokenizer_type: roberta_bytelevel_bpe
    pretrained_model_name_or_path: ./inputs/datasets/tokenizer_bases/
    do_lower_case: true
    add_pair_prefix_space: false
    max_length: 125
    tail_index: kernel
    use_magic: true
model:
    model_type: roberta-headtail-segmentation-v5
    pretrained_model_name_or_path: roberta-base
    num_output_units: 125
fobj:
    fobj_type: ce
fobj_segmentation:
    fobj_type: lovasz
optimizer:
    optim_type: adam
    lr: 0.00005
scheduler:
    scheduler_type: cosine
    every_step_unit: 0.5
train:
    use_offsets: true
    max_epoch: 5
    warmup_epoch: 0
    thresh_unit: 0.05  # no meaning for head tail
    rm_neutral: false
    ema_mu: 0.9
    ema_level: batch
    ema_n: 1  # < 1 means no ema
    accum_mod:
        - 1
        - 2
        - 2
        - 4
        - 4
    segmentation_loss_ratios:
        - 2.5
        - 2.5
        - 1.5
        - 1.5
        - 0.5
predict:
    use_offsets: true
    neutral_origin: false
    head_tail_equal_handle: tail
    pospro:
        head_tail_1: false
        req_shorten: false
        regex_3: false
        magic_2: true
    tail_index: kernel
