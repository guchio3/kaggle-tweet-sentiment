description: "cumsum segmentation again"
runner: r002
SINGLE_FOLD: false
split:
    split_type: abhishek5
    split_num: 5
    shuffle: true
    random_state: 71
loader:
    trn_sampler_type: random
    trn_batch_size: 96
    tst_sampler_type: sequential
    tst_batch_size: 96
    dataset_type: tse_headtail_segmentation_dataset_v4
dataset:
    tokenizer_type: roberta_bytelevel_bpe
    pretrained_model_name_or_path: ./inputs/datasets/
    do_lower_case: true
    add_pair_prefix_space: false
    max_length: 125
model:
    model_type: roberta-headtail-cumsum-segmentation
    pretrained_model_name_or_path: roberta-base
    num_output_units: 125
fobj:
    fobj_type: ce
fobj_segmentation:
    fobj_type: lovasz
optimizer:
    optim_type: adam
    lr: 0.00005 # 03
scheduler:
    # scheduler_type: every_step
    scheduler_type: cosine
    every_step_unit: 0.5
train:
    max_epoch: 5
    warmup_epoch: 0
    thresh_unit: 0.05  # no meaning for head tail
    rm_neutral: false
    ema_mu: 0.9
    ema_level: batch
    ema_n: 1  # < 1 means no ema
    accum_mod:
        - 1
        - 2
        - 4
        - 8
        - 16
    segmentation_loss_ratios: 1
predict:
    neutral_origin: true
    head_tail_equal_handle: tail
    use_offsets: false
    pospro:
        head_tail_1: false
        req_shorten: true
