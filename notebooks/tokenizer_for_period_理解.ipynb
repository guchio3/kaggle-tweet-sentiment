{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, RobertaModel\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27423, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>my_text</th>\n",
       "      <th>my_selected_text</th>\n",
       "      <th>my_text_eq_my_selected_text</th>\n",
       "      <th>predicted_texts</th>\n",
       "      <th>manual_selected_text</th>\n",
       "      <th>selected_text_lower</th>\n",
       "      <th>manual_and_selected_intersection_len</th>\n",
       "      <th>manual_and_selected_tokenized_intersection_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>True</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>False</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>False</td>\n",
       "      <td>bullying</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>False</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on th...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>False</td>\n",
       "      <td>sons of ****,</td>\n",
       "      <td>sons of ****,</td>\n",
       "      <td>sons of ****,</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                                             my_text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4  Sons of ****, why couldn`t they put them on th...   \n",
       "\n",
       "                      my_selected_text  my_text_eq_my_selected_text  \\\n",
       "0  I`d have responded, if I were going                         True   \n",
       "1                             Sooo SAD                        False   \n",
       "2                          bullying me                        False   \n",
       "3                       leave me alone                        False   \n",
       "4                        Sons of ****,                        False   \n",
       "\n",
       "                        predicted_texts                  manual_selected_text  \\\n",
       "0   i`d have responded, if i were going   i`d have responded, if i were going   \n",
       "1                              sooo sad                              sooo sad   \n",
       "2                              bullying                           bullying me   \n",
       "3                        leave me alone                        leave me alone   \n",
       "4                         sons of ****,                         sons of ****,   \n",
       "\n",
       "                    selected_text_lower  manual_and_selected_intersection_len  \\\n",
       "0   i`d have responded, if i were going                                     7   \n",
       "1                              sooo sad                                     2   \n",
       "2                           bullying me                                     2   \n",
       "3                        leave me alone                                     3   \n",
       "4                         sons of ****,                                     3   \n",
       "\n",
       "   manual_and_selected_tokenized_intersection_len  \n",
       "0                                               9  \n",
       "1                                               3  \n",
       "2                                               2  \n",
       "3                                               3  \n",
       "4                                               4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trn_df = pd.read_csv('../inputs/nes_info/e080_dataset_trn_df.csv').dropna()\n",
    "display(trn_df.shape, trn_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tools.tokenizers import myRobertaByteLevelBPETokenizer\n",
    "\n",
    "tokenizer = myRobertaByteLevelBPETokenizer(   \n",
    "    vocab_file='../inputs/datasets/roberta/tokenizer/vocab.json',\n",
    "    merges_file='../inputs/datasets/roberta/tokenizer/merges.txt',\n",
    "    lowercase=True,\n",
    "    add_prefix_space=True)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens([\n",
    "                '[S]',\n",
    "                '[PERIOD]',\n",
    "                '[EXCL]',\n",
    "                '[QUES]',\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>my_text</th>\n",
       "      <th>my_selected_text</th>\n",
       "      <th>my_text_eq_my_selected_text</th>\n",
       "      <th>predicted_texts</th>\n",
       "      <th>manual_selected_text</th>\n",
       "      <th>selected_text_lower</th>\n",
       "      <th>manual_and_selected_intersection_len</th>\n",
       "      <th>manual_and_selected_tokenized_intersection_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>42df3695a8</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>False</td>\n",
       "      <td>stupid.</td>\n",
       "      <td>ppl who smoke pot, are so f . . .n stupid. an...</td>\n",
       "      <td>ppl who smoke pot, are so f . . .n stupid. an...</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "11986  42df3695a8  Ppl who smoke pot, are so f . . .n stupid. An ...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "11986  Ppl who smoke pot, are so f . . .n stupid. An ...  negative   \n",
       "\n",
       "                                                 my_text  \\\n",
       "11986  Ppl who smoke pot, are so f . . .n stupid. An ...   \n",
       "\n",
       "                                        my_selected_text  \\\n",
       "11986  Ppl who smoke pot, are so f . . .n stupid. An ...   \n",
       "\n",
       "       my_text_eq_my_selected_text predicted_texts  \\\n",
       "11986                        False         stupid.   \n",
       "\n",
       "                                    manual_selected_text  \\\n",
       "11986   ppl who smoke pot, are so f . . .n stupid. an...   \n",
       "\n",
       "                                     selected_text_lower  \\\n",
       "11986   ppl who smoke pot, are so f . . .n stupid. an...   \n",
       "\n",
       "       manual_and_selected_intersection_len  \\\n",
       "11986                                    14   \n",
       "\n",
       "       manual_and_selected_tokenized_intersection_len  \n",
       "11986                                              17  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df[trn_df.selected_text_lower.str.contains(' \\. \\.')].query('sentiment != \"neutral\"').sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "row = trn_df.loc[11986]\n",
    "\n",
    "tweet_base = re.sub(r' \\.', '[S][PERIOD]', row['text'])\n",
    "tweet_base = re.sub(r'\\.', '[PERIOD]', tweet_base)\n",
    "tweet_base = re.sub(' !', '[S][EXCL]', tweet_base)\n",
    "tweet_base = re.sub('!', '[EXCL]', tweet_base)\n",
    "tweet = \" \" + \" \".join(tweet_base.split())\n",
    "selected_text_base = re.sub(r' \\.', '[S][PERIOD]', row['selected_text'])\n",
    "selected_text_base = re.sub(r'\\.', '[PERIOD]', selected_text_base)\n",
    "selected_text_base = re.sub(' !', '[S][EXCL]', selected_text_base)\n",
    "selected_text_base = re.sub('!', '[EXCL]', selected_text_base)\n",
    "selected_text = \" \" + \" \".join(selected_text_base.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ppl who smoke pot, are so f . . .n stupid. An instant turn off. drugs in general. why? seriously! ! ! why?\n",
      " Ppl who smoke pot, are so f[S][PERIOD][S][PERIOD][S][PERIOD]n stupid[PERIOD] An instant turn off[PERIOD] drugs in general[PERIOD] why? seriously[EXCL][S][EXCL][S][EXCL] why?\n",
      "Ppl who smoke pot, are so f . . .n stupid. An instant turn off.\n",
      " Ppl who smoke pot, are so f[S][PERIOD][S][PERIOD][S][PERIOD]n stupid[PERIOD] An instant turn off[PERIOD]\n"
     ]
    }
   ],
   "source": [
    "print(row['text'])\n",
    "print(tweet)\n",
    "print(row['selected_text'])\n",
    "print(selected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġp',\n",
       " 'pl',\n",
       " 'Ġwho',\n",
       " 'Ġsmoke',\n",
       " 'Ġpot',\n",
       " ',',\n",
       " 'Ġare',\n",
       " 'Ġso',\n",
       " 'Ġf',\n",
       " '[S]',\n",
       " '[PERIOD]',\n",
       " '[S]',\n",
       " '[PERIOD]',\n",
       " '[S]',\n",
       " '[PERIOD]',\n",
       " 'Ġn',\n",
       " 'Ġstupid',\n",
       " '[PERIOD]',\n",
       " 'Ġan',\n",
       " 'Ġinstant',\n",
       " 'Ġturn',\n",
       " 'Ġoff',\n",
       " '[PERIOD]']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(selected_text).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġ-']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('-').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37249]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('^').ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ppl who smoke pot, are so f . . .n stupid. An instant turn off.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = re.sub('\\[S\\]', ' ', selected_text) \n",
    "re.sub('\\[PERIOD\\]', '.', a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1476, -0.0365,  0.0753,  ..., -0.0023,  0.0172, -0.0016],\n",
       "        [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156],\n",
       "        [-0.0347, -0.0873, -0.0180,  ...,  0.1174, -0.0098, -0.0355],\n",
       "        ...,\n",
       "        [ 0.0304,  0.0504, -0.0307,  ...,  0.0377,  0.0096,  0.0084],\n",
       "        [ 0.0623, -0.0596,  0.0307,  ..., -0.0920,  0.1080, -0.0183],\n",
       "        [ 0.1259, -0.0145,  0.0332,  ...,  0.0121,  0.0342,  0.0168]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.word_embeddings.weight.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39934, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>old_text</th>\n",
       "      <th>textID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>c811396dc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>9063631ab1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>2a815f151d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>We want to trade with someone who has Houston...</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>82565a56d3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                               text  \\\n",
       "0       empty   i know  i was listenin to bad habit earlier a...   \n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2     sadness                Funeral ceremony...gloomy friday...   \n",
       "3  enthusiasm               wants to hang out with friends SOON!   \n",
       "4     neutral   We want to trade with someone who has Houston...   \n",
       "\n",
       "                                            old_text      textID  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...         NaN  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  c811396dc2  \n",
       "2                Funeral ceremony...gloomy friday...  9063631ab1  \n",
       "3               wants to hang out with friends SOON!  2a815f151d  \n",
       "4  @dannycastillo We want to trade with someone w...  82565a56d3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../inputs/datasets/w_private/tweet_sentiment_origin_merged.csv')\n",
    "display(df.shape, df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8588\n",
       "worry         8456\n",
       "happiness     5208\n",
       "sadness       5162\n",
       "love          3841\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          819\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_map_dict = {\n",
    "    'neutral': 'neutral',\n",
    "    'worry': 'negative',\n",
    "    'happiness': 'positive',\n",
    "    'sadness': 'negative',\n",
    "    'love': 'positive',\n",
    "    'surprise': 'positive',\n",
    "    'fun': 'positive',\n",
    "    'relief': 'positive',\n",
    "    'hate': 'negative',\n",
    "    'empty': 'negative',\n",
    "    'enthusiasm': 'positive',\n",
    "    'boredom': 'negative',\n",
    "    'anger': 'negative',\n",
    "}\n",
    "\n",
    "df = df.rename(columns={'sentiment': 'original_sentiment'})\n",
    "df['sentiment'] = df.original_sentiment.map(sentiment_map_dict)\n",
    "df.sentiment.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>old_text</th>\n",
       "      <th>textID</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>c811396dc2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>9063631ab1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>2a815f151d</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>We want to trade with someone who has Houston...</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>82565a56d3</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_sentiment                                               text  \\\n",
       "0              empty   i know  i was listenin to bad habit earlier a...   \n",
       "1            sadness  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2            sadness                Funeral ceremony...gloomy friday...   \n",
       "3         enthusiasm               wants to hang out with friends SOON!   \n",
       "4            neutral   We want to trade with someone who has Houston...   \n",
       "\n",
       "                                            old_text      textID sentiment  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...         NaN  negative  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  c811396dc2  negative  \n",
       "2                Funeral ceremony...gloomy friday...  9063631ab1  negative  \n",
       "3               wants to hang out with friends SOON!  2a815f151d  positive  \n",
       "4  @dannycastillo We want to trade with someone w...  82565a56d3   neutral  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    16049\n",
       "positive    15297\n",
       "neutral      8588\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textID'] = df['textID'].fillna('private')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../inputs/datasets/w_private/tweet_sentiment_origin_merged_guchio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tools.tokenizers import myRobertaByteLevelBPETokenizer\n",
    "\n",
    "tokenizer = myRobertaByteLevelBPETokenizer(   \n",
    "    vocab_file='../inputs/datasets/roberta/tokenizer/vocab.json',\n",
    "    merges_file='../inputs/datasets/roberta/tokenizer/merges.txt',\n",
    "    lowercase=True,\n",
    "    add_prefix_space=False)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41486]\n",
      "[5802]\n",
      "[29, 625, 1825]\n",
      "[17437]\n",
      "[1342, 25134, 43586]\n",
      "[11240]\n",
      "[12516]\n",
      "[7974]\n",
      "[605, 17649]\n",
      "[4022]\n",
      "[12557, 22627]\n",
      "[2755]\n",
      "[17693]\n",
      "[657]\n",
      "[18317]\n",
      "[1531]\n",
      "[33990]\n",
      "[4157]\n",
      "[298, 37055]\n",
      "[11098]\n",
      "[428, 3995, 1075]\n",
      "[40326]\n",
      "[5982, 14134]\n",
      "[3500]\n",
      "[8395]\n",
      "[6378]\n"
     ]
    }
   ],
   "source": [
    "sentiments = df.sentiment.unique()\n",
    "for sentiment in sentiments:\n",
    "    print(f' ------- sentiment: {sentiment} ------- ')\n",
    "    print(f'{tokenizer.encode(sentiment).ids}')\n",
    "    print(tokenizer.encode(f' {sentiment}').ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "a = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 50264, 2]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.encode('<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<mask>'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.decode([50264])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><pad></s>'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.decode([0, 1, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
