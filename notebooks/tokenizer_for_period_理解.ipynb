{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, RobertaModel\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27423, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>my_text</th>\n",
       "      <th>my_selected_text</th>\n",
       "      <th>my_text_eq_my_selected_text</th>\n",
       "      <th>predicted_texts</th>\n",
       "      <th>manual_selected_text</th>\n",
       "      <th>selected_text_lower</th>\n",
       "      <th>manual_and_selected_intersection_len</th>\n",
       "      <th>manual_and_selected_tokenized_intersection_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>True</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>False</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>False</td>\n",
       "      <td>bullying</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>False</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on th...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>False</td>\n",
       "      <td>sons of ****,</td>\n",
       "      <td>sons of ****,</td>\n",
       "      <td>sons of ****,</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                                             my_text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4  Sons of ****, why couldn`t they put them on th...   \n",
       "\n",
       "                      my_selected_text  my_text_eq_my_selected_text  \\\n",
       "0  I`d have responded, if I were going                         True   \n",
       "1                             Sooo SAD                        False   \n",
       "2                          bullying me                        False   \n",
       "3                       leave me alone                        False   \n",
       "4                        Sons of ****,                        False   \n",
       "\n",
       "                        predicted_texts                  manual_selected_text  \\\n",
       "0   i`d have responded, if i were going   i`d have responded, if i were going   \n",
       "1                              sooo sad                              sooo sad   \n",
       "2                              bullying                           bullying me   \n",
       "3                        leave me alone                        leave me alone   \n",
       "4                         sons of ****,                         sons of ****,   \n",
       "\n",
       "                    selected_text_lower  manual_and_selected_intersection_len  \\\n",
       "0   i`d have responded, if i were going                                     7   \n",
       "1                              sooo sad                                     2   \n",
       "2                           bullying me                                     2   \n",
       "3                        leave me alone                                     3   \n",
       "4                         sons of ****,                                     3   \n",
       "\n",
       "   manual_and_selected_tokenized_intersection_len  \n",
       "0                                               9  \n",
       "1                                               3  \n",
       "2                                               2  \n",
       "3                                               3  \n",
       "4                                               4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trn_df = pd.read_csv('../inputs/nes_info/e080_dataset_trn_df.csv').dropna()\n",
    "display(trn_df.shape, trn_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from tools.tokenizers import myRobertaByteLevelBPETokenizer\n",
    "\n",
    "tokenizer = myRobertaByteLevelBPETokenizer(   \n",
    "    vocab_file='../inputs/datasets/roberta/tokenizer/vocab.json',\n",
    "    merges_file='../inputs/datasets/roberta/tokenizer/merges.txt',\n",
    "    lowercase=True,\n",
    "    add_prefix_space=True)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens([\n",
    "                '[S]',\n",
    "                '[PERIOD]',\n",
    "                '[EXCL]',\n",
    "                '[QUES]',\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>my_text</th>\n",
       "      <th>my_selected_text</th>\n",
       "      <th>my_text_eq_my_selected_text</th>\n",
       "      <th>predicted_texts</th>\n",
       "      <th>manual_selected_text</th>\n",
       "      <th>selected_text_lower</th>\n",
       "      <th>manual_and_selected_intersection_len</th>\n",
       "      <th>manual_and_selected_tokenized_intersection_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>42df3695a8</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>Ppl who smoke pot, are so f . . .n stupid. An ...</td>\n",
       "      <td>False</td>\n",
       "      <td>stupid.</td>\n",
       "      <td>ppl who smoke pot, are so f . . .n stupid. an...</td>\n",
       "      <td>ppl who smoke pot, are so f . . .n stupid. an...</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "11986  42df3695a8  Ppl who smoke pot, are so f . . .n stupid. An ...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "11986  Ppl who smoke pot, are so f . . .n stupid. An ...  negative   \n",
       "\n",
       "                                                 my_text  \\\n",
       "11986  Ppl who smoke pot, are so f . . .n stupid. An ...   \n",
       "\n",
       "                                        my_selected_text  \\\n",
       "11986  Ppl who smoke pot, are so f . . .n stupid. An ...   \n",
       "\n",
       "       my_text_eq_my_selected_text predicted_texts  \\\n",
       "11986                        False         stupid.   \n",
       "\n",
       "                                    manual_selected_text  \\\n",
       "11986   ppl who smoke pot, are so f . . .n stupid. an...   \n",
       "\n",
       "                                     selected_text_lower  \\\n",
       "11986   ppl who smoke pot, are so f . . .n stupid. an...   \n",
       "\n",
       "       manual_and_selected_intersection_len  \\\n",
       "11986                                    14   \n",
       "\n",
       "       manual_and_selected_tokenized_intersection_len  \n",
       "11986                                              17  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df[trn_df.selected_text_lower.str.contains(' \\. \\.')].query('sentiment != \"neutral\"').sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "row = trn_df.loc[11986]\n",
    "\n",
    "tweet_base = re.sub(r' \\.', '[S][PERIOD]', row['text'])\n",
    "tweet_base = re.sub(r'\\.', '[PERIOD]', tweet_base)\n",
    "tweet_base = re.sub(' !', '[S][EXCL]', tweet_base)\n",
    "tweet_base = re.sub('!', '[EXCL]', tweet_base)\n",
    "tweet = \" \" + \" \".join(tweet_base.split())\n",
    "selected_text_base = re.sub(r' \\.', '[S][PERIOD]', row['selected_text'])\n",
    "selected_text_base = re.sub(r'\\.', '[PERIOD]', selected_text_base)\n",
    "selected_text_base = re.sub(' !', '[S][EXCL]', selected_text_base)\n",
    "selected_text_base = re.sub('!', '[EXCL]', selected_text_base)\n",
    "selected_text = \" \" + \" \".join(selected_text_base.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ppl who smoke pot, are so f . . .n stupid. An instant turn off. drugs in general. why? seriously! ! ! why?\n",
      " Ppl who smoke pot, are so f[S][PERIOD][S][PERIOD][S][PERIOD]n stupid[PERIOD] An instant turn off[PERIOD] drugs in general[PERIOD] why? seriously[EXCL][S][EXCL][S][EXCL] why?\n",
      "Ppl who smoke pot, are so f . . .n stupid. An instant turn off.\n",
      " Ppl who smoke pot, are so f[S][PERIOD][S][PERIOD][S][PERIOD]n stupid[PERIOD] An instant turn off[PERIOD]\n"
     ]
    }
   ],
   "source": [
    "print(row['text'])\n",
    "print(tweet)\n",
    "print(row['selected_text'])\n",
    "print(selected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġp',\n",
       " 'pl',\n",
       " 'Ġwho',\n",
       " 'Ġsmoke',\n",
       " 'Ġpot',\n",
       " ',',\n",
       " 'Ġare',\n",
       " 'Ġso',\n",
       " 'Ġf',\n",
       " '[S]',\n",
       " '[PERIOD]',\n",
       " '[S]',\n",
       " '[PERIOD]',\n",
       " '[S]',\n",
       " '[PERIOD]',\n",
       " 'Ġn',\n",
       " 'Ġstupid',\n",
       " '[PERIOD]',\n",
       " 'Ġan',\n",
       " 'Ġinstant',\n",
       " 'Ġturn',\n",
       " 'Ġoff',\n",
       " '[PERIOD]']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(selected_text).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġ-']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('-').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37249]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('^').ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ppl who smoke pot, are so f . . .n stupid. An instant turn off.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = re.sub('\\[S\\]', ' ', selected_text) \n",
    "re.sub('\\[PERIOD\\]', '.', a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1476, -0.0365,  0.0753,  ..., -0.0023,  0.0172, -0.0016],\n",
       "        [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156],\n",
       "        [-0.0347, -0.0873, -0.0180,  ...,  0.1174, -0.0098, -0.0355],\n",
       "        ...,\n",
       "        [ 0.0304,  0.0504, -0.0307,  ...,  0.0377,  0.0096,  0.0084],\n",
       "        [ 0.0623, -0.0596,  0.0307,  ..., -0.0920,  0.1080, -0.0183],\n",
       "        [ 0.1259, -0.0145,  0.0332,  ...,  0.0121,  0.0342,  0.0168]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.word_embeddings.weight.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
